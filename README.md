# ğŸ¼ CrySense AI â€” Baby Cry Analysis System

<div align="center">

![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

*An AI-powered system that analyzes baby cries to identify their emotional needs*

[Features](#-features) â€¢ [Installation](#-installation) â€¢ [Usage](#-usage) â€¢ [Model Architecture](#-model-architecture) â€¢ [Dataset](#-dataset)

</div>

---

## ğŸ“– Overview

**CrySense AI** is a deep learning-based system designed to classify baby cries into five emotional categories, helping parents and caregivers understand what their baby needs. Using audio analysis and convolutional neural networks, CrySense provides real-time predictions with confidence scores and actionable recommendations.

### ğŸ¯ Cry Categories

- **ğŸ¼ Hungry** - Baby needs feeding
- **ğŸ˜´ Sleepy** - Baby is tired and needs rest
- **ğŸ‘¶ Diaper** - Diaper change required
- **âš ï¸ Pain** - Baby may be experiencing discomfort or pain
- **ğŸ‘• Discomfort** - Environmental factors (temperature, clothing, etc.)

---

## âœ¨ Features

- **Deep Learning Model** - CNN-based architecture for audio classification
- **Real-time Analysis** - Process audio files or live recordings
- **Confidence Scoring** - Get probability scores for each prediction
- **PDF Reports** - Auto-generated analysis reports
- **Web Interface** - User-friendly Gradio UI for easy interaction
- **Batch Processing** - Analyze multiple audio files recursively
- **Visual Insights** - Mel spectrogram-based audio feature extraction

---

## ğŸš€ Installation

### Prerequisites

- Python 3.8 or higher
- CUDA-compatible GPU (optional, for faster training)

### Step 1: Clone the Repository

```bash
git clone https://github.com/yourusername/crysense-ai.git
cd crysense-ai
```

### Step 2: Install Dependencies

```bash
pip install torch torchvision torchaudio
pip install soundfile librosa gradio reportlab numpy
```

### Step 3: Verify Installation

```bash
python -c "import torch; print(f'PyTorch {torch.__version__} installed successfully')"
```

---

## ğŸ“‚ Project Structure

```
crysense-ai/
â”‚
â”œâ”€â”€ train.py                    # Model training script
â”œâ”€â”€ inference.py                # Prediction engine
â”œâ”€â”€ utils.py                    # Recommendation system
â”œâ”€â”€ generate_report.py          # PDF report generator
â”œâ”€â”€ test_inference.py           # Batch testing script
â”‚
â”œâ”€â”€ web/
â”‚   â”œâ”€â”€ app.py                  # Gradio web interface
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html          # HTML template
â”‚
â”œâ”€â”€ cry_model.pth               # Trained model weights (generated)
â””â”€â”€ README.md                   # This file
```

---

## ğŸ“ Usage

### 1ï¸âƒ£ Training the Model

Place your dataset in the following structure:

```
Baby Crying Sounds/
â”œâ”€â”€ hungry/
â”‚   â”œâ”€â”€ audio1.wav
â”‚   â”œâ”€â”€ audio2.wav
â”‚   â””â”€â”€ ...
â”œâ”€â”€ sleepy/
â”œâ”€â”€ diaper/
â”œâ”€â”€ pain/
â””â”€â”€ discomfort/
```

Update the `DATASET_DIR` in `train.py` and run:

```bash
python train.py
```

**Training Configuration:**
- Sample Rate: 16,000 Hz
- Batch Size: 8
- Epochs: 15
- Learning Rate: 0.001

### 2ï¸âƒ£ Single Audio Prediction

```python
from inference import predict_audio

prediction, confidence, probabilities = predict_audio("baby_cry.wav")
print(f"Prediction: {prediction} ({confidence*100:.1f}% confident)")
```

### 3ï¸âƒ£ Batch Testing

Test multiple audio files recursively:

```bash
python test_inference.py
```

This will:
- Scan the dataset directory for all `.wav` files
- Run predictions on each file
- Generate PDF reports for each analysis
- Display results in the console

### 4ï¸âƒ£ Web Interface

Launch the interactive web app:

```bash
cd web
python app.py
```

Then open your browser to `http://localhost:7860`

**Features:**
- Upload audio files (`.wav`, `.mp3`)
- Record directly from microphone
- View analysis results with recommendations
- Download PDF reports

---

## ğŸ§  Model Architecture

### Audio Processing Pipeline

1. **Audio Loading** - Load `.wav` files using `soundfile`
2. **Resampling** - Normalize to 16kHz sample rate
3. **Mel Spectrogram** - Convert waveform to 64-band mel spectrogram
4. **Padding/Truncation** - Standardize to 500 time frames
5. **Feature Extraction** - CNN processes spectral features
6. **Classification** - Fully connected layer outputs 5 class probabilities

### Network Architecture

```
Input: Mel Spectrogram (500 x 64)
    â†“
Conv1D (64â†’128, kernel=5, stride=2) + ReLU
    â†“
Conv1D (128â†’256, kernel=5, stride=2) + ReLU
    â†“
MaxPool1D (kernel=2)
    â†“
Global Average Pooling
    â†“
Fully Connected (256â†’5)
    â†“
Softmax â†’ [hungry, sleepy, diaper, pain, discomfort]
```

**Model Highlights:**
- Lightweight CNN design for real-time inference
- Mel spectrogram feature representation
- Global average pooling reduces overfitting
- Adam optimizer with cross-entropy loss

---

## ğŸ“Š Dataset

The model is trained on the **Baby Crying Sounds** dataset containing labeled audio samples across five categories.

### Dataset Requirements

- **Format:** `.wav` files
- **Duration:** 2-6 seconds recommended
- **Sample Rate:** 16 kHz (auto-resampled if different)
- **Classes:** 5 balanced categories

### Data Organization

```
DATASET_DIR/
â”œâ”€â”€ hungry/          # Feeding-related cries
â”œâ”€â”€ sleepy/          # Tired/drowsy cries
â”œâ”€â”€ diaper/          # Diaper change needed
â”œâ”€â”€ pain/            # Pain/distress cries
â””â”€â”€ discomfort/      # General discomfort
```

---

## ğŸ“ˆ Results & Analysis

### Confidence Levels

- **HIGH** (â‰¥80%): Strong prediction, immediate action recommended
- **MEDIUM** (60-79%): Likely correct, monitor situation
- **LOW** (<60%): Uncertain, consider multiple factors

### Recommendations System

Each prediction comes with actionable guidance:

| Category | Recommendation |
|----------|----------------|
| **Hungry** | ğŸ¼ Offer feeding. Watch for rooting/sucking cues. |
| **Pain** | âš ï¸ Check for fever, rash, swelling. Consult pediatrician if persistent. |
| **Sleepy** | ğŸ˜´ Dim lights, swaddle, reduce stimulation. |
| **Discomfort** | ğŸ‘• Check diaper, clothing, room temperature. |
| **Diaper** | ğŸ‘¶ Change diaper and ensure comfort. |

---

## ğŸ”§ Configuration

### Key Parameters (editable in scripts)

```python
SAMPLE_RATE = 16000      # Audio sample rate
BATCH_SIZE = 8           # Training batch size
EPOCHS = 15              # Training epochs
LEARNING_RATE = 0.001    # Optimizer learning rate
N_CLASSES = 5            # Number of cry categories
MAX_LEN = 500            # Mel spectrogram time frames
```

---

## ğŸ“ Report Generation

Automated PDF reports include:
- Predicted cry type with confidence score
- Timestamp of analysis
- Audio file information
- Recommendation guidelines
- System metadata

Example usage:

```python
from generate_report import create_report

pdf_path = create_report(
    prediction="hungry",
    confidence=0.87,
    file_in="baby_cry.wav"
)
```

---

## ğŸ› ï¸ Development

### Adding New Cry Categories

1. Update `CLASS_NAMES` in `train.py`
2. Increment `N_CLASSES`
3. Add corresponding folder to dataset
4. Update `RECOMMENDATIONS` in `utils.py`
5. Retrain the model

### Improving Model Performance

- **Data Augmentation:** Add noise, time-stretching, pitch shifting
- **Deeper Architecture:** Add more convolutional layers
- **Transfer Learning:** Use pre-trained audio models
- **Ensemble Methods:** Combine multiple model predictions

---

## âš ï¸ Important Notes

### Research Prototype

This system is designed for **research and educational purposes**. It should not replace professional medical advice or caregiver judgment.

### Limitations

- Performance depends on audio quality and recording conditions
- Model accuracy varies with background noise levels
- Cultural and individual differences in baby cries may affect results
- Always prioritize direct observation and professional guidance

---

## ğŸ¤ Contributing

Contributions are welcome! Please follow these steps:

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/improvement`)
3. Commit your changes (`git commit -am 'Add new feature'`)
4. Push to the branch (`git push origin feature/improvement`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License. See `LICENSE` file for details.

---

## ğŸ™ Acknowledgments

- Dataset: Baby Crying Sounds Archive
- Frameworks: PyTorch, Gradio, librosa
- Audio Processing: torchaudio, soundfile

---

## ğŸ“§ Contact

For questions, suggestions, or collaboration:

- **GitHub Issues:** [Report bugs or request features](https://github.com/AneeshaIyer/CrySense/issues)
- **Email:** aneeshamiyer@gmail.com -- batulhsuratwala@gmail.com

---

<div align="center">

**Made with â¤ï¸ for parents and caregivers everywhere**

â­ Star this repo if you find it helpful!

</div>
